# AIT 発表 台本

## タイトル

### はじめに

情報技術の進歩により、街には多くのカメラが設置されている。しかし、長時間の動画から必要な部分を確認するためには多くの時間を要する。
そこで、必要な場面のみを抽出するシステムがあれば、様々な場面で活用できるのではないかと考えた。また、必要な動画のみを保存することでデータ容量を減らすことができる。
まずは身近な動物の動画を題材とし、動物園や子どもたちの学習に活用できるようなシステムを開発することにした。

### 研究内容

#### 概要

<!-- TODO: lapsquash のロゴを右上に置く. -->

こちらが開発した lapsquash のシステム全体図です.  
lapsquash というのはタイムラプスを圧縮するという意味で, ロゴのデザインを行いました.

このシステムではまず, 動物行動の動画を細分化します.
ビデオクリップは、時間のメタデータとオブジェクトストレージに保存します.
次に、保存されたデータから、ビデオクリップごとにタイル状に並べた画像を生成します.
タイル画像を Bard の Image Input API で分析、動物行動に分類し、メタデータに書き込みます.
最後に、分類し短縮されたビデオクリップを Web アプリ上に表示します.

### 研究内容

#### 動物行動

はじめに既存の論文を参考にし, 動物行動を 8 つに分類しました.
しかし、長時間の動画をそのまま AI で分類することは、データ量が大きく難しい。そのため、まずは、必要な動きのある場面のみを抽出することにしました.
動物行動の変化の境目は、類似度ハッシュを利用して検出しました.
続いて、動画のタイル化と圧縮を行いました。AI のインプット用にビデオクリップから時間ごとのタイル画像を生成します。これにより、画像入力ができる Bard に解析できるようになりました。

★
その後、行動分析をするために、Bard の Image Input API を使用して、タイル画像の特徴と説明、事前に私たちで決めたタグ付けを AI にしてもらいます。これらの結果は先ほどのデータに再格納することで、Web アプリで見られるようにしました。

#### 閲覧 Web アプリケーション

こちらが行動の解析結果とダイジェストを見るためのアプリケーションです.
はじめに見たい映像を選択すると閲覧画面に移行し, 右側に分類された行動ごとのビデオクリップが選択できます.
選択すると左側にその映像が再生されます.

### 研究結果・検証

その結果、定点カメラにより撮影されたニホンザルの 30 分間の映像の総時間は切り抜き前より 47% 短くなり、ヒツジの 30 分間の映像の総時間は切り抜き前より 64% 短くなりました.
このことから, データ容量の削減と確認するための大幅な時間や労力の削減が可能であることがわかりました.

★  
10 月 22 日 東山動物園にご協力いただき、4 名の職員の方にシステムのプレゼンテーションを行いました。
飼育員の方のご意見では、今回使用した分類の方法では曖昧な点が多く、動物行動の定義付けに関する難しさをご指摘いただきました。
そのため、汎用的なシステムよりも、特定の動物に特化した行動分析を行うシステムの方が有用であること、映像に加えて音声を解析することで、精度を高めることにつながるとのご意見も頂きました。
今回、飼育員の方の活用だけでなく、子どもの学習の活用も目指していましたが、これに対しても必要な情報が異なるため、飼育員用と来園者用でシステムを分ける必要があると分かりました。

### おわりに
