# 論文

## 論文題目名

- AI による動画短縮のための場面抽出分類システム開発

## 本文

### はじめに

近年、映像技術の発達に伴い、誰でも長時間の動画を撮影できるようになった。しかし、長時間の動画の場合、重要な場面を見返すことは効率的ではない。効率的に見返せるようにするために自動的に場面を抽出できるシステムを開発した。抽出した動画に説明を付けて、 Web アプリ上に表示する。今回は動物を対象に設定した。理由は動物の場合、動いている部分のみを抽出することで彼らが何を考えて行動しているのか、またその行動にどのような意味があるのか。動物について理解を深められると考えた。この研究を応用して、中学生までの子供を対象に動物園の事前学習に応用に利用でき、動物行動の研究に繋がるだけでなく、幅広い分野の分析・分類やペットの安全を確認するカメラとしての活用、必要な部分のみを動画として保存するため、容量の節約なども期待できると考える。

[メモ](東山動植物園で実際に働く職員の方々にアドバイスをいただいた。実際に働く人の意見を聞くことで自分たちが想定していなかった部分も知ることができた。)

### 目的

動物園に行って動いていなかった動物の動きをアプリ上で閲覧可能にすることで、対象の動物が日頃どのような動きをしているのか、
またその動きにどのような理由があるのかを来場者や体の不自由な人が　 Web アプリを通して知ってもらうこと。
動物園の職員さんの業務の中に「動物の檻の中で撮影した動画を見てノート(日記？)を書く」というものがあるらしく、2–3 時間必要だと聞いたため、業務の負担を軽減すること、  
中学生までの子供を対象に動物園の事前学習への応用、動物の行動についての研究や天文学などの異なる分野の分析・分類に活用することを最終的な目的としている。

### 研究・活動の内容（概要）

動物園の動物は夜行性も多く、動いていないことが多い。来場者が見たい行動を起こすタイミングは未知であるため、辛抱強く待ったが結局来場者が見たかった行動を見ることができず動物園を後にしてしまう可能性がある。普段どのような行動をどのぐらいの時間帯にしているのかを映像で確認できれば来場者が見たい行動をしている時間に観に行き、その姿を観察することで動物園を回る効率が上がり、問題を解消できるのではないか。
このような想いから動物園の動物の動画を常時撮影し、動いている部分だけをリアルタイムで抽出し　閲覧できる Web アプリを開発した。

研究の手順としては

1. 動物の動きをカメラモジュールで撮影し, それをオブジェクトストレージに保存
2. ビデオクリップを細分化
3. 動物行動を AI で分析
4. 解析したデータを Web アプリ上に表示

という手順を踏んで動いている。
システムは、撮影に Raspberry Pi、動画分析には Bard の Image Input API を利用した。 長時間の動画から自動的に活動シーンだけを切り抜き、AI を用いて分析・分類しアプリとして表示する。
分類した映像に事前に私たちが設定したタグに分類し、抽出した動画が何を写しているのか一目でわかるようになっている。 AI を用いて行動についての説明も追加し、学習にも役立つアプリとした。

### 研究・活動の目的を果たすための調査・活動方法（計画）　　（s ０、s １、s ２の「この図はプログラムの設計を....のところ」画像貼る）

[ここ画像必要](1-2-3枚目の画像)リアルタイムで動画を細分化するには、カメラで長時間の動画を撮影する必要がある。しかし、長時間の動画を AI で解析させるのはリソースが限られているため技術的に難しい。そのためまず必要な動きのある場面のみを抽出することにした。ここに　 3 枚の行動の画像がある。 1 から 2 枚目の変化は微量だが、 2 から 3 枚目は行動が変化している。
動物行動の変化の境目を検出するため、 今回は 2 つのトリガーをハイブリッド方式で適用した。

[ここ画像必要](s0 s1 s2 の画像)1 つ目は類似度ハッシュを利用して検出する方法。類似度ハッシュは、 画像の特徴を抽出してハッシュ値に変換する関数であり、
同じ画像であれば値は一致し、 違う画像であれば輝度や色、 輪郭の変化によって少しずつ変化する。s0、s1 のように画像が変化した場合も検出できる。
隣り合う画像のハッシュの差を取れば、s1、s2 　の間に大きな変化があることが確認できる。
しかし、 s1、s2 　のように画像の背景のみが変化した場合でもハッシュが変化してしまうため、
2 つ目に最新の物体検出モデル YOLO v8 を使用し、 類似度ハッシュと合わせて観察対象のみの動きを捉えることにした。
しかし、 YOLO v8 では処理が遅すぎて動画の書き出しに影響が出たため、 今回は類似度ハッシュのみをトリガーとした。

[ここ画像必要](学会発表の時に使ったプログラムの画像)この図はプログラムの設計を表している。レンダラーとモデルが事前に定義したインターフェースを継承して実装した。
図から、 レンダラーもモデルもイベントループを継承している。
レンダラー抽象クラスは、　初期化処理と画面描画、 1 フレームごとの画面更新を行うメソッドを持つ。 またモデル抽象クラスは、 初期化処理と 1 フレームごとの更新処理と終了処理を行うメソッドを持つ。
組み立てやすくするためにモデルの定義はモデル抽象クラスを継承することで、 モデルを拡張機能のように扱うことができるため分離性が高まる。 これによって複雑な処理を内容によって分離でき、 パッケージ化できるようにした。

また、 イベントループ抽象クラスのコンストラクタにシングルトンストアを注入することで、 継承しているレンダラーやモデル内で簡単にシングルトンストアを使用可能になり、 モデル内で安全にステートの読み書きができるようにした。これによって後続のモデルにデータを渡しやすくなった。
これらの設計の工夫によって、 リアルタイム性に優れた OpenCV や PyQtGraph, PySide などの適切なフレームワークを組み合わせて表示できました。

動画の切り抜き範囲を決めるアルゴリズム
1 フレームごとに類似度ハッシュ算出される。 類似度ハッシュの変化を知るために過去 1 秒の類似度ハッシュの値を最小二乗法で近似し、 その傾きを求める。
開発当初は決めたしきい値で切り抜きを行っていたが、 動画によって最適なしきい値が異なるため、 過去の傾きから指数移動平均を取って動的な切り抜きを始める方法に変更した。

動画のタイル化・圧縮を行った。 AI のインプット用にビデオクリップから時間ごとのタイル画像を生成する。これにより、 画像入力ができる Bard が解析可能になる。

ビデオクリップとタイル画像、メタデータをひとまとめにしたファイルをオブジェクトストレージである SharePoint に保存する。
SharePoint は、 Graph API という API エンドポイント経由でアクセスが可能。OAuth 2.0 に準拠するように実装したため、 ユーザーが squasher や viewer にアクセス権限の委任をすることで、 離れたところでも安全にデータを保存が可能になっている。

その後、 AI に行動分析をさせ、 Bard の Image Input API を使用し、 タイル画像の特徴と説明、 事前に私たちで決めたタグ付けを行う。
これらの結果は、 先ほどのメタデータに再格納することにより、 Web アプリで閲覧できるようになる。

viewer では lapsquash ファイルを読み込み、動画を閲覧可能。 また、AI が生成した説明やタグを一緒に確認することにより、動物が何をしているのか、また、その行動の意味が分かりやすくなっている。

[ここ画像必要](発表の時に使ったUIの画面の画像)viewer のデザインについて。 Material Design を一部採用し、 ニューモフィズムと丸みを持たせたデザインにすることによって操作しやすく、 親しみやすいアプリにした。 また、インタラクティブな UI にすることでパソコン操作が苦手な人でも直感的な操作が可能になっている。
一画面に squasher で得たデータを実際の映像と同時に確認することで動物がなにをしているのかや行動の意味を確認しやすくなっている。

Material Design を採用することで、デバイスの画面サイズに合わせてデザインを最適化しやすいように装飾を減らし、シンプルなデザインを基本としている。そのため、別のデバイスで使用する時でも操作が容易となっている。それに加え ニューモフィズム デザインを採用することで Material Design のシンプルさに加え UX の向上を図った。ニューモフィズムとは Material Design のようなフラットデザインに凹凸を加えたデザインのことである。これを採用することで操作性の向上や他のアプリとの UI での差別化をした。
Web サイトで閲覧するため、画面サイズによってレスポンシブに UI が変化するように設計した。配色には Material Design の Color System を採用することでコンテンツ数が増えた際でも視認性を保つことができた。
実際に動物園の職員の方に画面を見せた際、「見やすい」と、評価を貰った。

[ここ画像必要](発表の時に使った UI の画面の説明の画像　色ついてるやつ)
次に画面の構成について。 この画面ではプロジェクトを一覧表示でき、 動物ごとのダイジェストを確認することが可能となっている。
プロジェクトを開くとこのような画面になっている。 右側には動画を時系列に並べ、 選択することでその動画を閲覧できる。 左下側では動画と説明やタグを確認することが可能。

実際のアプリの動作だ。 プロジェクトを開くと、 閲覧画面に移行し、 squasher が切り抜いた動画を閲覧出来る。 右側で切り抜いたシーンを選択することが可能で、自分が見たい場面のみを閲覧できる。

以上のように、 今回のシステムは大きく分けて 3 つの部分から構成されている。
また、 今学期にチームで分かりやすく全体図を制作した。

squasher は Raspberry Pi 上で動いており、 viewer は好きな デバイス で動く。
しかし、 analyzer はエッジ関数として、 世界中のどこからでも実行できるようになっている。
工夫点としては, エッジ関数としての analyzer のコードが git submodule として, 他の squasher や viewer のコードに組み込まれていることだ。 analyzer の API を tRPC で記述することによって, 他のどちらからでも型安全に呼び出すことができる。

本研究では、 長時間撮影された動物の動画を使用し、 AI 技術を用いて分析・分類し、 必要な動画のみを確認できるシステムを開発する。また、 分析結果のダイジェストは、 アプリケーションを介して誰でも閲覧できるようにすることで、 動物園の課題解決にも取り組む。

### 調査・活動の実施内容と成果

研究期間中は、 カメラモジュールからの動画を Raspberry Pi を使用して対象の動物が動いている場面のみを抽出、細分化して圧縮し、 アップロードを行い、 動画を Bard の Image Input API で分析する。また、 分析結果と共にストレージへ保存し、 lapsquash 　アプリで AI が生成した説明の文章とともに表示される。

### 考察・研究・活動についての想定（計画）と結果の比較対照

### おわりに

動物園の職員の方々の話を聞いた際、画面の動きだけでなく、音の分析・分類ができると動物の観察に役立つと聞いた。音の分析についてはあまり重要性を感じなかったが、動物の鳴き声は種類、性別、年齢時期などで鳴き方や声色が変わるとのこと。
今後研究していく過程で鳴き声の分析・分類や、夜間暗い中での分析、寝ていることの多い動物が寝ているか生きているかの見分けも行なっていく。
現状, 切り抜き範囲が細かすぎるなどの問題や, 実際に AI に説明させてみたところ, 抽象的な説明しかできなかった。  
今後は, 切り抜きのアルゴリズムとプロンプトの改善, タイル画像のフレーム数とそのサイズの調整が必要である。

参考文献

- [ニホンザル野生群の日周活動リズム](https://www.jstage.jst.go.jp/article/ase1911/79/2/79_2_128/_pdf)
- [友好関係にある仲間に.......の根拠](https://www.jstage.jst.go.jp/article/janip/63/2/63_63.2.4/_pdf/-char/ja)
- [ニホンザルが毛づくろいをする理由](https://www.osaruland.jp/tips/1820/)
- [ニホンザルの毛づくろい](https://jinrui.zool.kyoto-u.ac.jp/Arashiyama/guide.html)
- [ニホンザルってどんな動物？](https://jinrui.zool.kyoto-u.ac.jp/Arashiyama/whatisJmacaque.html)
- [ニホンザルの分布](https://jinrui.zool.kyoto-u.ac.jp/FuscataHome/bunpu.html#:~:text=%E6%97%A5%E6%9C%AC%E3%81%AB%E7%94%9F%E6%81%AF%E3%81%99%E3%82%8B%E3%82%B5%E3%83%AB,%E5%BA%83%E3%81%8F%E5%88%86%E5%B8%83%E3%81%97%E3%81%A6%E3%81%84%E3%81%BE%E3%81%99%E3%80%82)
- [睡眠](https://jigokudani-yaenkoen.co.jp/contents/detail?id=117) -[毛ずくろいしらみを....](http://repository.tufs.ac.jp/bitstream/10108/89011/1/field-16_p18-19.pdf)
- ニホンザルの基礎生態と特定計画策定・運用のポイントについて  
  ref: [東北野生動物保護管理センター](https://www.env.go.jp/nature/choju/effort/effort5/effort5-3b/4_0130_saru.pdf)
- チンパンジーとニホンザルの違いについて  
  ref: [絶滅危惧種リスト](https://endangered-species.biz/archives/2457)
- チンパンジーとヒトの共通点・相違点 : 社会的知性を中心に  
  ref: [京都大学学術情報リポジトリ](https://repository.kulib.kyoto-u.ac.jp/dspace/bitstream/2433/148029/1/100_145.pdf)
- ニホンザルの生態と生息環境について  
  ref: [滋賀県](https://www.pref.shiga.lg.jp/file/attachment/1010347.pdf)
- ニホンザルの定点カメラ映像  
  ref: [YouTube](https://www.youtube.com/live/IjMWzpyCNZM?feature=share)
