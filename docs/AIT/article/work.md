# 論文

## 論文題目名

- AI による動画短縮のための場面抽出分類システム開発

## 本文

### はじめに

情報技術の進歩により、街には多くのカメラが設置されている。しかし、長時間の動画から必要な部分を確認するためには多くの時間を要する。
そこで、必要な場面のみを抽出するシステムがあれば、様々な場面で活用できるのではないかと考えた。また、必要な動画のみを保存することでデータ容量を減らすことができる。
まずは身近な動物の動画を題材とし、動物園や子どもたちの学習に活用できるようなシステムを開発することにした。

### 目的

先行研究[^1]では、MPEG 動画から画像を複合せずにマクロブロック (映像の処理単位) から動画のカットを試みている。
しかし、この方法では、MPEG 動画のみにしか対応ができない。私たちは、MPEG 動画だけでなく、カメラ映像からリアルタイムに解析、抽出することによって動画を短縮し、
AI を用いて分類するシステムを開発する。また、誰でも簡単に活用できるよう、Web のアプリケーションとする。

### 研究・活動の内容 (概要)

<!-- textlint-disable ja-technical-writing/no-doubled-joshi -->

まず、動物の動きを Raspberry Pi のカメラモジュールで撮影し、細分化する。ビデオクリップは、時間のメタデータとオブジェクトストレージに保存する。
次に、保存されたデータから、ビデオクリップごとにタイル状に並べた画像を生成する。タイル画像を Bard の Image Input API で分析、動物行動に分類し、メタデータに書き込む。
最後に、分類し短縮されたビデオクリップを Web アプリ上に表示する (図 1)。

<!-- textlint-enable -->

<img src="./assets/img/7.png" width="600" title="図1: 全体図" />

### 研究・活動の目的を果たすための調査・活動方法 (計画)

#### 動物行動

既存の論文[^2][^3][^4][^5][^6][^7][^8][^9][^10][^11]を参考にし、動物行動を 8 つに分類した (表 1)。

| タグ | 行動                   |
| ---- | ---------------------- |
| $F$  | 採食                   |
| $S$  | 座る                   |
| $G$  | 毛づくろい             |
| $Sl$ | 睡眠                   |
| $Q$  | 喧嘩                   |
| $M$  | 動く、跳ぶ、走る、歩く |
| $P$  | 遊ぶ                   |
| $C$  | 交尾                   |

<!-- 表 1: 動物行動の分類 -->

しかし、長時間の動画をそのまま AI で分類することは、データ量が大きく難しい。そのため、まずは、必要な動きのある場面のみを抽出することにした。
動物行動の変化の境目は、類似度ハッシュを利用して検出した。類似度ハッシュは、画像の特徴を抽出してハッシュ値に変換する関数である。
隣り合う画像のハッシュ値の差によって、画像の変化とみなせる (図 2)。

<img src="./assets/img/2.png" width="600" title="図2: 類似度ハッシュの変化率を用いた行動変化の境界検出" />

1 フレームごとに算出された類似度ハッシュの変化を得るために、過去 1 秒の類似度ハッシュ値を最小二乗法の 1 次式で近似し、その傾きを算出した。
開発当初は、静的なしきい値で切り抜きを行っていたが、動画によって最適なしきい値が異なるため、過去の傾きから指数移動平均を算出し、動的なしきい値を使用した切り抜きを行う方法に変更した。
プログラムの処理内容を図 3 に示す。

<img src="./assets/img/3.png" width="600" title="図3: Squasher Core のフレーム毎の処理" />

レンダラーとモデルが事前に定義したインターフェースを継承して、切り抜きを行うプログラムを制作した。レンダラー抽象クラスは、
初期化処理と画面描画、1 フレームごとの画面更新をするメソッドを持つ。また、モデル抽象クラスは、初期化処理と 1 フレームごとの更新処理と終了処理を行うメソッドを持つ。
モデルの定義はモデル抽象クラスを継承することで、モデルを拡張機能のように扱えるため、分離性が高まった。これにより複雑な処理を内容ごとに分離し、パッケージ化できた。

また、イベントループ抽象クラスのコンストラクタにシングルトンストアを注入することで、継承しているレンダラーとモデル内で簡単にシングルトンストアを利用可能になり、モデル内で安全にステートの読み書きができるようになった。
これらの設計の工夫によって、後続のモデルにデータを渡しやすくなり、リアルタイム性に優れた OpenCV や PyQtGraph、PySide などの適切なフレームワークを組み合わせて、データの可視化も行った (図 4)。

<img src="./assets/img/4.png" width="600" title="図4: Squasher Core のアーキテクチャ" />

#### 動画のタイル化

AI のインプット用にビデオクリップからタイル画像を生成する。これにより、Bard で解析可能になる。解析が終了したタイル画像のメタデータに、ビデオクリップごとの特徴と説明とタグのデータを再格納する。
これらのファイルをオブジェクトストレージである SharePoint に保存する。SharePoint は、Graph API 経由でアクセスが可能である。OAuth 2.0 に準拠するように実装し、
ユーザーが squasher や viewer にアクセス権限の委任をすることで、ネットワーク上で安全にデータを保存できる。これによりタグ付けされたビデオクリップを Web のアプリケーションで閲覧できるようになった。

#### 閲覧 Web アプリケーション (Viewer)

<img src="./assets/img/5.png" width="600" title="図5: Viewer の外観" />

オブジェクトストレージからファイルを読み込み、AI が生成した説明やタグをわかりやすく表示した。Material Design を一部採用し、ニューモフィズムと丸みを持たせたデザインにすることによって操作しやすく、
親しみやすいアプリにした。ニューモフィズムとはフラットデザインに凹凸を加えたデザインのことである。また、インタラクティブな UI にすることでパソコン操作が苦手な人でも直感的な操作が可能になっている。
デバイスの画面サイズに合わせてデザインを最適化しやすいように装飾を減らし、シンプルなデザインを採用した。配色にも Material Design の Color System を採用することでコンテンツ数が増えた際でも視認性を保つことができた。

### 調査・活動の実施内容と成果

#### 切り抜きアルゴリズムの精度検証

Squasher Core の切り抜きアルゴリズムの精度を検証するために、動画に対して `(始点 [秒], 終点 [秒])` の範囲データを定めた。
人の手で切り抜いた範囲データと Squasher Core が切り抜いた範囲データを比較し、両者の一致率を算出した。また、許容される誤差の範囲を 1 秒とした。
その結果、定点カメラにより撮影されたニホンザルの 30 分間の動画 (おさるランド＆アニタウン) の精度は 43.5 %、ヒツジの 30 分間の動画 (石狩ひつじ牧場) の精度は、54.4 % となった。

#### AI によるタグ付けの精度検証

タグ付けについては、未検証である。その理由は、様々な行動の含まれた動画がなく、検証が難しかったためである。

#### 動物園での意見交換

<img src="./assets/img/8.png" width="600" title="図8: 意見交換会の様子" />

2023 年 10 月 22 日 (日) 東山動物園にご協力いただき、飼育を担当されている 3 名の方にシステムのプレゼンテーションを行った。
飼育員の方のご意見では、今回使用した分類の方法ではあいまいな点が多く、動物行動の定義付けに関する難しさをご指摘いただいた。そのため、汎用的なシステムよりも、
特定の動物に特化した行動分析を行うシステムの方が有用だとわかった。また、映像に加えて、音声を解析することで、精度を高めることにつながるとのご意見も頂いた。
今回、飼育員の方の活用だけでなく、子どもの学習の活用も目指したが、これに対しても、必要な情報が異なるため、システムを分ける必要だとわかった。

### 考察・研究・活動についての想定 (計画) と結果の比較対照

動物行動の変化の境目を検出するためのトリガーとして類似度ハッシュを採用したが、切り抜きアルゴリズムとしての想定した精度を発揮できなかった。
そこで、最新の物体検出モデル YOLO v8 とのハイブリッド方式で行うのがよいと考えた。類似度ハッシュは画像の背景のみが変化した場合でも変化してしまう。それに対して、最新の物体検出モデル YOLO v8 を使用することで、
類似度ハッシュと合わせて観察対象のみの動きを捉えることができた。しかし、実際に制作し、動作を確認したところ YOLO v8 では処理が遅く動画の書き出しに影響が出たため、類似度ハッシュのみをトリガーとしたが、
今後精度の向上には YOLO v8 よりも処理の速い物体検出の仕組みを追加すべきである。

ビデオクリップの長さが 3–4 秒となった結果、AI が動物の行動を解析するのに十分な量の情報が取得できず、当初予想していたようなタグ付けができなかった。
今後は、ビデオクリップの適切な長さを研究し改善する。また、AI が生成した説明は、青いコンテナの上で歩いているサルの動画を「水槽の中にいるサル」といった説明であった。
そのままの生成 AI を利用するには精度の限界があるため、今後は特定の動物の行動を学習させたモデルを使用する。

### おわりに

情報技術の進歩は日進月歩であり、長時間の映像から必要な部分を効率的に抽出するシステムの需要は今後、高まるはずである。この需要に応えるため、本研究ではそのシステムの開発を試みた。
その結果、人の手による切り抜きデータと Squasher Core の切り抜きアルゴリズムの比較による精度検証では 40–50 % という結果が得られた。また、AI によるタグ付けの精度は未検証であり、今後の調査が必要である。
さらに、東山動物園の飼育員との意見交換会では、特定の動物に特化した行動分析と音声解析の導入の提案があり、システムを適切な大きさで分割する必要だとわかった。

今後の課題は、動画の切り出しのアルゴリズムとして、画像の類似度ハッシュと物体検出を組み合わせ、十分な解析速度を有するシステムの開発を目指す。
AI がタグ付けを行う際に必要十分なデータとして、複数のカメラ映像、音声データを加え、解析の質を向上させ、タグ付けの精度を高める研究をする。

### (参考文献)

<!--
  - 著者名・発行年・タイトル・出版社
  - 著者名・発行年・タイトル・URL・アクセス年月日
  - 著者名・発行年・記事名・雑誌名・号数・出帆社
-->

<!-- textlint-disable -->

[^1]: 椎尾 一郎 ・ 1996 年 ・ 予測ブロック数を利用した MPEG 動画像カット検出法 ・ 全国大会講演論文集 ・ メディア情報処理 / 52 回 ・ 情報処理学会
[^2]: 岩野泰三、四元伸子、西田利貞 ・ 1971 年 ・ ニホンザル野生群の日周活動リズム ・ 人類誌 ・ 79-2 ・ J. Anthrop. Soc. Nippon
[^3]: おさるランド & アニタウン ・ 2020 年 ・ ニホンザルが毛づくろいをする理由 ・ <https://www.osaruland.jp/tips/1820/> ・ 2023 年 6 月 6 日閲覧
[^4]: 宇野壮春、清野紘典 ・ 2014 年 ・ ニホンザルの基礎生態と特定計画策定・運用のポイントについて ・ <https://www.env.go.jp/nature/choju/effort/effort5/effort5-3b/4_0130_saru.pdf> ・ 2023 年 5 月 30 日閲覧
[^5]: 人類進化論研究室 ・ 2016 年 ・ 分布-ニホンザルホームページ ・ <https://jinrui.zool.kyoto-u.ac.jp/FuscataHome/bunpu.html> ・ 2023 年 6 月 6 日閲覧
[^6]: 地獄谷野猿公苑 ・ 2023 年 ・ ニホンザルの一日 ・ <https://jigokudani-yaenkoen.co.jp/contents/detail?id=117> ・ 2023 年 8 月 11 日閲覧
[^7]: 山本、真也 ・ 2011 年 ・ チンパンジーとヒトの共通点・相違点 : 社会的知性を中心に ・ 人文學報 ・ 100 ・ KURENAI
[^8]: 滋賀県 ・ 2003 年 ・ ニホンザルの生態と生息環境について ・ <https://www.pref.shiga.lg.jp/file/attachment/1010347.pdf> ・ 2023 年 5 月 30 日閲覧
[^9]: おさるランド ・ 2022 年 ・ 猿山 ライブカメラ ・ <https://www.youtube.com/watch?v=IjMWzpyCNZM> ・ 2023 年 9 月 12 日閲覧
[^10]: 石狩ひつじ牧場 OFFICIAL CHANNEL ・ 2023 年 ・ ひつじの親子の楽しい生活をライブで（No.1 カメラ） ・ <https://www.youtube.com/watch?v=8gHdcDgNnJg> ・ 2023 年 10 月 17 日閲覧
[^11]: 吉田 信明、田中 正之、和田 晴太郎 ・ 2014 年 ・ 行動記録を通じた動物の理解のための動物園動物観察アプリケーションの開発 ・ 情報処理学会研究報告 ・ No.11 ・ 情報処理学会
