# 中間発表 台本

中間発表の作業フォルダー ([SharePoint](https://tiny.cc/lapsq-sh/docs/1_midterm))

## はじめ / 0m13s / マチダ

発表を始めます.

私たちは, **AI による動画短縮のための場面抽出分類システム開発** の研究を行っています.

まず, 研究の経緯です.

## 1. 経緯, 目的 / 1m02s / スズキ

★  
動物園に行ったとき, 見に行った動物が動いていなかったり, 動いているが行っている行動の意味が分からなかったりすることあると思います.  
これらの行動を分析し, PC アプリ上に表示させることで動物たちが何を考え, 行動しているのかの理解を深められると考えました.

★  
この課題を解決するために図のように…

1. 動物の動きをカメラモジュールで撮影し, それをオブジェクトストレージに保存する
2. ビデオクリップを細分化する
3. 動物行動を AI で分析させる
4. 解析したデータを PC アプリ上に表示させる

というような流れで研究を進めています.

★  
このシステムを使うことで, 動物についてもっと理解してもらえるようになり, また, 入場者に楽しんでもらえるようになると考えます.  
また, 見つけた生態傾向が新しい生態傾向の発見に繋がったり, 他の動物との共通点を見つける手助けになると考えます.

これらが達成できたら, 将来的には動物の生態観察や行動分析に活用されるよう, 精度と分類の詳細性を向上させる予定です.

## 2. 今学期やったこと

### チーム結成 / 0m15s

★  
まず, 私たちはチームの結成をしました.  
バックエンドとフロントを担当するマチダと, フロントエンドを担当するオサカダくん, 文書の作成や UI デザインなどを担当する私です. この 3 人で進んでいます.

### システム名称の決定 / 0m14s

★  
目的にあったように, タイムラプスを 圧縮する つまり squash するという意味で, lapsquash という名称に決定しました.  
この名称はマチダが提案し, この爽やかなロゴは, 私が制作しました.

### 実装の概要 / 0m05s / マチダ

★  
経緯, 目的 から, 具体的な実装を説明します.

#### 1. 動物の動きを撮影する / 0m22s

まず, 動物行動の変化を捉えるために, Raspberry Pi とカメラモジュールを用いて動物の動きを撮影します.  
写真のようにカメラモジュールをリボンケーブルで繋ぎ, Raspberry Pi に接続します.  
こんな感じです. はい.  
このようにして動物の行動は撮影できるっぽそうですが, 解析させる上では, 複数の問題があります.

#### 2. リアルタイムで細分化 / 1m38s -> 1m25s

★  
まず, 長時間の動画を AI で効率良く解析させるのは技術的に難しいです. リソースが限られていますからね.  
なので, 必要な動きのある場面だけを抽出すれば良くなりそうです.  
★  
このように 3 枚の行動の画像があります. 1 から 2 枚目は変化は無さそうですが, 2 から 3 枚目は行動が変化しています.  
では, 動物行動の変化の境目を検出するには何をトリガーにすれば良いでしょうか…？  
現時点では, 以下の 2 つのトリガーをハイブリッド方式で適用する予定です.

★  
1 つ目は類似度ハッシュを利用して検出する方法です.  
類似度ハッシュは, 画像の特徴を抽出して, それをハッシュ値に変換する関数です.  
同じ画像であれば値は一致し, 違う画像であれば, 輝度や色, 輪郭の変化によって, 少しずつ変化します.  
例えば、画像 $s_0$ と $s_1$ のように画像が変化した場合も検出できます.  
しかし、$s_1$ と $s_2$ のように画像の背景のみが変化した場合でも、ハッシュが変化してしまいます.  
そこで最新の物体検出モデル YOLO v8 を使用し, 類似度ハッシュと合わせて, 観察対象のみの動きを捉えるようにしました.

さてこのようにして, 動物の動きを撮影し, 動きの変化を検出できるようになりました.
これで, 長時間の動画を細分化でき, AI に解析させやすくなりました.

#### 3. 動画のタイル化・圧縮 / 0m33s

★  
そのあと, AI のインプット用にビデオクリップから時間ごとのタイル画像を生成します.  
これは, 現時点で ChatGPT が画像のインプットしかできないためです.  
タイルの大きさや枚数の調整が今後の課題ですね.  
★  
そしたら, ビデオクリップとタイル画像, メタデータをひとまとめに圧縮します.  
このフォーマットは完全に独自のものです. ここでいうメタデータはいわば箱のようなもので, 後々この箱に AI の解析結果が入り, PC アプリで見れるようにするために使います.

#### 4. ストレージサーバーへ保存 / 0m29s

★  
そしたら, この圧縮したファイルをストレージサーバーに保存します. 今回はオブジェクトストレージである SharePoint に保存します. SharePoint は, Graph API という API エンドポイント経由でアクセスできます.  
OAuth 2.0 に準拠するように実装したので, ユーザーが squasher や viewer にアクセス権限の委任をすることで, 離れたところでも安全にデータを保存できます.

#### 5. AI に行動分析をさせる / 0m24s

★  
その後, AI に行動分析をさせます. ChatGPT-4 の Image Input API を使用して, タイル画像の特徴と説明, 事前に私たちで決めたタグ付けを AI にしてもらいます.  
これらの結果は, 先ほどのメタデータに再格納することで, PC アプリで見れるようにします.  
これらがスムーズにできるようにすることが今後の課題ですね.

#### 6. アプリで見れるようにする / 0m15s

★  
最後に, 行動の解析結果とダイジェストを PC アプリで見れるようにします.  
適切なアクセス権限を持ったアカウントでログインすることで, オブジェクトストレージからデータを取得し, ダイジェストなどを見れるようにします.  
画面に写っているのは Figma で制作した UI デザインです.  
このデザイン案通りにニューモーフィズムな UI を実装することが今後の課題ですね.

以上のように, 今回のシステムは大きく分けて 3 つの部分から構成されています.  
また, 今学期にチームで分かりやすく全体図を制作しました.

### システム全体図 / 0m15s / オサカダ

★  
これが lapsquash 全体図です.

(ほどよい沈黙)

...次に, それぞれの部分の技術スタックを見てみましょう.

### 技術スタック / 0m37s

★  
技術スタックは表の通りです.  
https://prod.liveshare.vsengsaas.visualstudio.com/join?9A14F50ED026BA9D4E30D5F6F3EA551F70B0

それでは, それぞれのタスクと実装済みのものを見てみましょう.

### それぞれのタスク / 0m09s

★
表の通りです.

(ほどよい沈黙)

...さて, その他にも今学期やったことがあるので紹介します.

### その他 / 0m34s

★  
私たちの研究は, 電気学会 基礎・材料・共通部門大会 に出ることなっています.  
そのため, 出場するために必要なアブストと全体図を制作し, 提出しました.

また, この研究では, それぞれのシステムのソースコードとプロジェクト進行に必要な情報を, 別々の git リポジトリで管理しています.  
さらに, タスク管理として GitHub Projects を使っています.  
これらの情報は, すべて GitHub の Organization である lapsquash に集約されています.

では, 今後の予定を見てみましょう.

## 3. 今後の予定 / 0m19s

★  
おおむね 7 - 8 月中にはシステムの完成を目指しています.  
細分化に必要な しきい値や AI 分析のためのプロンプトの調整に時間が掛かるので, そこに時間を割けるように研究を進めたいです.
またシステム開発と並行してスズキくんが随時, 進捗や実測データをまとめる予定です.

## おわり / 0m07s

★  
以上が私たちの研究の中間発表です. ご清聴ありがとうございました.
